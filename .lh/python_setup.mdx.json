{
    "sourceFile": "python_setup.mdx",
    "activeCommit": 0,
    "commits": [
        {
            "activePatchIndex": 0,
            "patches": [
                {
                    "date": 1728436361862,
                    "content": "Index: \n===================================================================\n--- \n+++ \n"
                }
            ],
            "date": 1728436361862,
            "name": "Commit-0",
            "content": "This guide provides a streamlined approach to using the Chunkr API for document processing and analysis with Python.\nThe way you use the API is by creating a task for each document you want to process, and then polling the task status until it is completed.\nCheckout our github [repo](https://github.com/lumina-ai-inc/chunkr) for more examples and to view the full code.\n\n## Setup\n\n1. **Create an Account and Get API Key**\n\n   Go to [chunkr.ai](https://chunkr.ai) and create an account. Once logged in, navigate to your account settings or API section to obtain your API key.\n\n2. **Set Up Environment Variables**\n\n   Create a `.env` file in your project directory and add your API key:\n\n   ```bash\n   echo \"INGEST_SERVER__API_KEY=your_api_key_here\" > .env\n   echo \"INGEST_SERVER__URL=https://api.chunkr.ai\" >> .env\n   ```\n\n   Replace `your_api_key_here` with the actual API key you obtained from chunkr.ai.\n\n3. **Create the Script**\n\n   Create a new file named `process_documents.py` and copy the following code into it:\n\n   ```python\n   import os, requests, time, glob, json\n   from dotenv import load_dotenv\n\n   load_dotenv(override=True)\n\n   def get_base_url(): return os.getenv(\"INGEST_SERVER__URL\")\n   def get_headers(): return {\"Authorization\": os.getenv(\"INGEST_SERVER__API_KEY\")}\n\n   def create_task(file_path):\n       with open(file_path, \"rb\") as file:\n           response = requests.post(f\"{get_base_url()}/api/task\",\n               files={\"file\": (os.path.basename(file_path), file, \"application/pdf\")},\n               data={\"model\": \"HighQuality\", \"target_chunk_length\": 0},\n               headers=get_headers()\n           )\n       if response.status_code != 200:\n           raise Exception(f\"API request failed with status code {response.status_code}: {response.text}\")\n       return response.json()[\"task_url\"]\n\n   def get_task(task_url): return requests.get(task_url, headers=get_headers()).json()\n\n   def save_to_json(output, file_name):\n       output_json_path = os.path.join(os.path.dirname(__file__), \"output\", f\"{file_name}_json.json\")\n       os.makedirs(os.path.dirname(output_json_path), exist_ok=True)\n       json.dump(output, open(output_json_path, \"w\"))\n       return output_json_path\n\n   def process_files():\n       for file_path in glob.glob(os.path.join(\"input\", \"*.{pdf,docx,xlsx,xls,doc,ppt,pptx}\")):\n           try:\n               task_url = create_task(file_path)\n               while True:\n                   task = get_task(task_url)\n                   if task[\"status\"] == \"Succeeded\":\n                       output = task.get(\"output\")\n                       if output is None: raise Exception(f\"Output not found for {file_path}\")\n                       output_json_path = save_to_json(output, os.path.basename(file_path).split(\".\")[0])\n                       break\n                   if task[\"status\"] in [\"Failed\", \"Canceled\"]:\n                       break\n                   time.sleep(1)\n           except Exception as e:\n               print(f\"Error processing {file_path}: {str(e)}\")\n\n   if __name__ == \"__main__\": process_files()\n   ```\n\n4. **Install Required Packages**\n\n   Install the necessary Python packages:\n\n   ```bash\n   pip install requests python-dotenv\n   ```\n\n5. **Prepare Input Files**\n\n   Create an `input` folder in the same directory and place your PDF files there.\n\n6. Run the script to start processing:\n\n   ```bash\n   python process_documents.py\n   ```\n\n7. The script will process all PDF files in the `input` folder:\n\n   - It creates a task for each PDF file\n   - Monitors the task status\n   - When a task succeeds, it downloads the output (bounding boxes) and saves it as a JSON file in the `output` folder\n\n8. Check the console output for processing status and any error messages.\n\n9. Once completed, you'll find the JSON output files in the `output` folder, named after the original PDF files.\n10. To annotate the PDF with the bounding boxes, you can use the `annotate_pdf.py` script in our github [repo](https://github.com/lumina-ai-inc/chunkr/blob/main/pyscripts/annotate.py)\n\n11. Here's an example of an annotated PDF with bounding boxes:\n\n![Annotated PDF Example](sample2.png)\n\nThis image shows a PDF document with bounding boxes drawn around the detected text regions, demonstrating the output of the annotation process.\n"
        }
    ]
}