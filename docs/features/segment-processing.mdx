---
title: Segment Processing
description: "Post-processing of segments"
---

Chunkr processes files by converting them into chunks, where each chunk contains a list of segments. This basic unit allows our API to be very flexible. See more information in the [Layout Analysis](./layout-analysis/segmentation_strategy.mdx) section.

After the segments are identified you can easily configure many post-processing capabilities. You can use our defaults or configure how each segment type is processed.

#### Processing Methods

- **Vision Language Models (VLM)**: Leverage AI models to generate HTML/Markdown content and run custom prompts
- **Heuristic-based Processing**: Apply rule-based algorithms for consistent HTML/Markdown generation

#### Additional Features

- **Cropping**: Get back the cropped images
- **Content to embed**: Configure the content that will be used for chunking and embeddings

Our default processing works for most documents, and RAG use cases.

> **Note**: Chunkr currently does not support creating embeddings, the embed_sources field will populate the `embed` field for the `chunk`.

## Understanding the configuration

When you configure the `SegmentProcessing` settings, you are configuring how each segment type is processed.
This means that anytime a segment type is identified, the configuration will be applied.

These are all the fields that are available for configuration:

```python
GenerationConfig(
    format=SegmentFormat.MARKDOWN,
    strategy=GenerationStrategy.AUTO,
    crop_image=CroppingStrategy.AUTO,
    llm=None,
    embed_sources=[EmbedSource.CONTENT],
    extended_context=False,
)
```

### Defaults

By default, Chunkr applies the following processing strategies for each segment type.
You can override these defaults by specifying custom configuration in your `SegmentProcessing` settings.
Generated content and OCR text are always returned. Extended context is off by default for all outputs.

<CodeGroup>
```python Table
# Tables by default are processed using LLM and generate HTML.
# Formulas are returned as LaTeX.

default_table_config = GenerationConfig(
    format=SegmentFormat.HTML,
    strategy=GenerationStrategy.LLM,
    crop_image=CroppingStrategy.AUTO,
    llm=None,
    embed_sources=[EmbedSource.CONTENT],
    extended_context=False
)

default_config = Configuration(
    segment_processing=SegmentProcessing(
        Table=default_table_config,
    )
)
```

```python Page and Formula
# Page and Formula by default are processed using LLM and returned as Markdown.
# Formulas are converted to LaTeX in both HTML and Markdown.

default_llm_config = GenerationConfig(
    html=GenerationStrategy.LLM,
    markdown=GenerationStrategy.LLM,
    crop_image=CroppingStrategy.AUTO,
    llm=None,
    embed_sources=[EmbedSource.CONTENT],
    extended_context=False
)

default_config = Configuration(
    segment_processing=SegmentProcessing(
        Page=default_llm_config,
        Formula=default_llm_config,
    )
)
```

```python Picture
# Pictures by default are processed using Auto and are cropped by default.
default_picture_config = GenerationConfig(
    format=SegmentFormat.MARKDOWN,
    strategy=GenerationStrategy.AUTO,
    crop_image=CroppingStrategy.ALL,
    llm=None,
    embed_sources=[EmbedSource.CONTENT],
    extended_context=False
)

default_config = Configuration(
    segment_processing=SegmentProcessing(
        Picture=default_picture_config
    )
)
```

```python Other Elements
# All other elements content is processed using heuristics and returned as Markdown.

default_text_config = GenerationConfig(
    format=SegmentFormat.MARKDOWN,
    strategy=GenerationStrategy.AUTO,
    crop_image=CroppingStrategy.AUTO,
    llm=None,
    embed_sources=[EmbedSource.CONTENT]
)

default_config = Configuration(
    segment_processing=SegmentProcessing(
        Title=default_text_config,
        SectionHeader=default_text_config,
        Text=default_text_config,
        ListItem=default_text_config,
        Caption=default_text_config,
        Footnote=default_text_config,
        PageHeader=default_text_config,
        PageFooter=default_text_config,
    )
)
```
</CodeGroup>

### SegmentFormat

The `SegmentFormat` enum determines the output format for the generated content. It has two options:

- `SegmentFormat.HTML`: Generate HTML content for the segment
- `SegmentFormat.MARKDOWN`: Generate Markdown content for the segment

### GenerationStrategy

The `GenerationStrategy` enum determines how Chunkr processes and generates output for a segment. It has two options:

- `GenerationStrategy.LLM`: Uses a Vision Language Model (VLM) to analyze and generate descriptions of the segment content. This is particularly useful for complex segments like tables, charts, and images where you want AI-powered understanding.

- `GenerationStrategy.AUTO`: Uses rule-based heuristics to process the segment. This is faster and works well for straightforward content like plain text, headers, and lists.

You can configure both the format and strategy for each segment type using the `format` and `strategy` fields in the configuration.

This is how you can access the generated content and OCR text in the segment object:

```python
for chunk in task.output.chunks:
    for segment in chunk.segments:
        print(segment.content)  # Generated content in the chosen format (HTML or Markdown)
        print(segment.text)     # OCR-extracted text
```

### CroppingStrategy

The `CroppingStrategy` enum controls how Chunkr handles image cropping for segments. It offers two options:

- `CroppingStrategy.ALL`: Forces cropping for every segment, extracting just the content within its bounding box.

- `CroppingStrategy.AUTO`: Lets Chunkr decide when cropping is necessary based on the segment type and post-processing requirements.
  For example, if an LLM is required to generate content from tables then they will be cropped.

```python
for chunk in task.output.chunks:
    for segment in chunk.segments:
        print(segment.image)
```

> **Note**: By default the `image` field contains a presigned URL to the cropped image that is valid for 10 minutes.
> You can also retrieve the image data as a base64 encoded string by following our [best practices guide](/sdk/data-operations/get#best-practices).

### LLM Prompt

The `llm` field is used to pass a prompt to the LLM. This prompt is independent of the `GenerationStrategy` and will be applied to all segment types that have the `llm` field set.

If you need extended context for LLM processing, you must explicitly enable it by setting `extended_context=True` in your `GenerationConfig`. Extended context requires a page image to be available at runtime.

Extended context is particularly useful for:

- Tables where legends aren't properly segmented
- Images that need surrounding page context for interpretation
- Charts or diagrams that reference information elsewhere on the page
- When segments need to "understand" their position in relation to other content

> **Note**: The `llm` prompts can sometimes mess with the LLMs and cause refusals. If your tasks are failing, try changing the `llm` prompt.

### Embed Sources

The `embed_sources` field is used to specify the sources of content that will be used for embeddings.
This is useful if you want to use a different source of content for embeddings than the default generated content.
They will also be used to calculate the chunk length during chunking. See more information in the [chunking](./chunking#calculating-chunk-lengths-with-embed-sources) section.

The embed sources is an array of sources. The index of the source will be used to determine which source appears first in the `embed` field.

For example, if you have `[EmbedSource.CONTENT, EmbedSource.LLM]`, the generated content will appear first in the `embed` field.
By default, the `embed` field will only contain the generated content.

```python Python
for chunk in task.output.chunks:
    print(chunk.embed)
```

> **Note**: This is the only configuration option that affects the `chunk` object rather than the `segment` object.
>
> When you set the `embed_sources` field:
>
> - You determine what content from segments will be included in the `embed` field of chunks
> - The order of sources in the array controls which content appears first in the `embed` field
> - This does not change the order of segments within chunks - reading order is always preserved
>
> For example, if you set `embed_sources=[EmbedSource.LLM, EmbedSource.CONTENT]` for Tables, the LLM-generated content will appear before the generated content in the `embed` field of any chunk containing a Table segment.

### Extended Context

The `extended_context` flag controls whether Chunkr provides the full page context when processing a segment. When set to `True`, Chunkr will use the entire page image as context when processing the segment with an LLM.

Extended context is OFF by default for all segment types. To leverage extended context, you must explicitly set `extended_context=True` within the `GenerationConfig` for the desired segment type(s).

Extended context is particularly beneficial for:

- **Tables/Charts with External Legends**: When a legend or explanatory text is located elsewhere on the page but is crucial for interpreting the table/chart.
- **Images Requiring Surrounding Context**: For images where understanding the surrounding text or other visual elements is necessary for accurate description or analysis.
- **Formulas/Diagrams**: When the meaning depends on adjacent text or figures.

<CodeGroup>
```python Python
from chunkr_ai.models import Configuration, GenerationConfig, GenerationStrategy, SegmentProcessing, SegmentFormat

config = Configuration(
    segment_processing=SegmentProcessing(
        Table=GenerationConfig(
            format=SegmentFormat.MARKDOWN,
            strategy=GenerationStrategy.LLM,
            extended_context=True,  # Enable extended context
        ),
        Picture=GenerationConfig(
            format=SegmentFormat.HTML,
            strategy=GenerationStrategy.LLM,
            extended_context=True,  # Enable extended context
        )
        # ... other segment configs
    )
)
```

```bash cURL
curl -X POST https://api.chunkr.ai/api/v1/task \
  --header "Authorization: YOUR_API_KEY" \
  --header "Content-Type: application/json" \
  --data '{
    "file": "base64_or_url_to_file",
    "segment_processing": {
      "Table": {
        "format": "Markdown",
        "strategy": "LLM",
        "extended_context": true
      },
      "Picture": {
        "format": "Html",
        "strategy": "LLM",
        "extended_context": true
      }
    }
  }'
```
</CodeGroup>

## Example

Here is a quick example of how to use Chunkr to process a document with different segment processing configurations.
This configuration will:

- Summarize the key trends of all `Table` segments and populate the `llm` field with the LLM content in the segment
- Enable extended context for Tables and Pictures to capture visual context from the full page
- The `embed` field for chunks that contain a `Table` segment will contain both the LLM content and the generated content,
  with the LLM content appearing first.
- Crop all `SectionHeader` segments to the bounding box.
- All other segments will use their default processing.

<CodeGroup>
```python Python
from chunkr_ai import Chunkr
from chunkr_ai.models import (
    Configuration,
    CroppingStrategy,
    EmbedSource,
    GenerationConfig,
    GenerationStrategy,
    SegmentProcessing,
    SegmentFormat
)

chunkr = Chunkr()

chunkr.upload("path/to/file", Configuration(
    segment_processing=SegmentProcessing(
        Table=GenerationConfig(
            format=SegmentFormat.MARKDOWN,
            strategy=GenerationStrategy.LLM,
            llm="Summarize the key trends in this table including any context from legends or surrounding text",
            embed_sources=[EmbedSource.LLM, EmbedSource.CONTENT],
            extended_context=True
        ),
        Picture=GenerationConfig(
            format=SegmentFormat.HTML,
            strategy=GenerationStrategy.LLM,
            crop_image=CroppingStrategy.ALL,
            extended_context=True,
        ),
        SectionHeader=GenerationConfig(
            crop_image=CroppingStrategy.ALL
        ),
    ),
))
```

```bash cURL
curl -X POST https://api.chunkr.ai/api/v1/task \
  --header "Authorization: YOUR_API_KEY" \
  --header "Content-Type: application/json" \
  --data '{
    "file": "base64_or_url_to_file",
    "segment_processing": {
      "Table": {
        "format": "Markdown",
        "strategy": "LLM",
        "llm": "Summarize the key trends in this table including any context from legends or surrounding text",
        "embed_sources": ["LLM", "Content"],
        "extended_context": true
      },
      "Picture": {
        "format": "Html",
        "strategy": "LLM",
        "crop_image": "All",
        "extended_context": true
      },
      "SectionHeader": {
        "crop_image": "All"
      }
    }
  }'
```
</CodeGroup>