---
title: Usage Limits
sidebarTitle: Limits
description: "Task timeouts and file size restrictions."
---

Chunkr is designed for high-throughput processing. In general there are no file size or page count limits, but there are a few considerations that are discussed here.

## Task Timeout

All tasks are subject to a **10-minute** timeout. If a task does not complete within this time, it will automatically fail.

If you have a file that consistently times out, please [contact our support team](mailto:support@chunkr.ai) to discuss potential solutions.

---

## Rate Limiting

To ensure fair usage and system stability, we enforce a rate limit of **10 files per second**. If you exceed this limit, our API will respond with a `429 Too Many Requests` error.

Our Python SDK is designed to handle this gracefully. It automatically detects `429` errors and retries the request after a short backoff period. This means you can upload files in a loop without implementing your own rate-limiting logic.

<CodeGroup>
```python Python
from chunkr_ai import Chunkr

client = Chunkr()

# The SDK will automatically handle rate limiting for you.
# No extra code is needed.

for i in range(20):
    task = client.tasks.parse.create(
        file=f"https://example.com/file_{i}.pdf"
    )
    print(f"Created task {task.task_id}")
```

```typescript TypeScript
import ChunkrAI from 'chunkr-ai';

const client = new ChunkrAI();

// The SDK will automatically handle rate limiting for you.
// No extra code is needed.

for (let i = 0; i < 20; i++) {
    const task = await client.tasks.parse.create({
        file: `https://example.com/file_${i}.pdf`
    });
    console.log(`Created task ${task.taskId}`);
}
```

```bash cURL
# Shell script with basic rate limiting
for i in {1..20}; do
    curl -X POST https://api.chunkr.ai/api/v1/tasks/parse \
      -H "Authorization: Bearer YOUR_API_KEY" \
      -H "Content-Type: application/json" \
      -d "{
        \"file\": \"https://example.com/file_${i}.pdf\"
      }"
    
    # Add a small delay to avoid rate limiting
    sleep 0.1
done
```
</CodeGroup>

---

## File Size Limits

In general, there are no hard limits on the size of the files you can upload. Our architecture is built to handle large files by processing them in parallel. However, there is one exception:

*   **Base64 Uploads**: When uploading a file as a base64-encoded string, the total request size is limited to **1GB**. This is a practical limit to ensure reliable transfer over HTTP.

If you need to upload files larger than 1GB, we recommend using a URL or uploading the file first, then creating a task with the uploaded file URL.

<CodeGroup>
```python Python
from chunkr_ai import Chunkr

client = Chunkr()

# Recommended for large files - use URL directly
task = client.tasks.parse.create(
    file="https://example.com/very-large-file.pdf"
)

# Or upload file first
with open("path/to/very/large/file.pdf", "rb") as f:
    uploaded_file = client.files.create(file=f)
    task = client.tasks.parse.create(
        file=uploaded_file.url
    )

# Avoid base64 for large files (>1GB will fail)
# task = client.tasks.parse.create(
#     file=f"data:application/pdf;base64,{large_base64_string}"
# )
```

```typescript TypeScript
import ChunkrAI from 'chunkr-ai';
import fs from 'fs';

const client = new ChunkrAI();

// Recommended for large files - use URL directly
const task1 = await client.tasks.parse.create({
    file: 'https://example.com/very-large-file.pdf'
});

// Or upload file first
const fileStream = fs.createReadStream('path/to/very/large/file.pdf');
const uploadedFile = await client.files.create({ file: fileStream });
const task2 = await client.tasks.parse.create({
    file: uploadedFile.url
});

// Avoid base64 for large files (>1GB will fail)
// const task = await client.tasks.parse.create({
//     file: `data:application/pdf;base64,${largeBase64String}`
// });
```

```bash cURL
# Recommended for large files - use URL directly
curl -X POST https://api.chunkr.ai/api/v1/tasks/parse \
  -H "Authorization: Bearer YOUR_API_KEY" \
  -H "Content-Type: application/json" \
  -d '{
    "file": "https://example.com/very-large-file.pdf"
  }'

# Or upload file first (for local files)
# Step 1: Upload the file
curl -X POST https://api.chunkr.ai/api/v1/files \
  -H "Authorization: Bearer YOUR_API_KEY" \
  -F "file=@path/to/very/large/file.pdf"

# Step 2: Use the returned URL to create a task
curl -X POST https://api.chunkr.ai/api/v1/tasks/parse \
  -H "Authorization: Bearer YOUR_API_KEY" \
  -H "Content-Type: application/json" \
  -d '{
    "file": "<URL_FROM_UPLOAD_RESPONSE>"
  }'

# Avoid base64 for large files (>1GB will fail)
```

</CodeGroup>

---

## Page Limits

There are **no page limits** for documents. Our parallel processing architecture allows us to handle documents with any number of pages, from a single page to thousands.
