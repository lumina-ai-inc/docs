---
title: Parse Overview
description: Convert documents into LLM-ready data
sidebarTitle: Overview
---

The Parse feature transforms complex documents into structured data that LLMs can read.

<Frame>Parsing image</Frame>

It intelligently identifies document elements, processes them based on their type, and outputs clean, structured content ready for AI applications and downstream workflow automation.

## Key Features

- **Perfect Markdown & HTML**: LLM-ready content (Markdown, HTML, tables, etc).
- **Reading order intact**: Maintains the natural reading flow for complex layouts.
- **Granular bounding boxes**: Pinpoints element coordinates with precision for easy citations.
- **Native Spreadsheet handling**: 100% reconstruction with formulas, styling, and cell values preserved; precise ranges; cleans tables and converts charts to structured data.
- **Post-processing**: Token-aware chunking, cropped images, and more.

## Example: Parse and access chunk content

Here's how you can parse a document and access its chunks using our SDKs.

<CodeGroup>
```python Python
from chunkr_ai import Chunkr

# Initialize the client with your API key
client = Chunkr(api_key="your_api_key")

# Parse a document from URL or local file
url = "https://example.com/document.pdf"
task = client.tasks.parse.create(file=url)

# OR parse from local file
# with open("path/to/document.pdf", "rb") as f:
#     file = client.files.create(file=f)
#     task = client.tasks.parse.create(file=file.url)

print(f"Task created with ID: {task.task_id}")

# Wait for the task to complete
task = client.tasks.get(task_id=task.task_id, wait_for_completion=True)

# Access the chunks from the output
if task.status == "Succeeded":
    print(f"Document has {len(task.output.chunks)} chunks.")
    # `chunk.content` holds the structured representation of document elements
    for chunk in task.output.chunks:
        print(chunk.content)
else:
    print(f"Task failed with status: {task.status}")
```

```typescript TypeScript
import Chunkr from 'chunkr-ai';
import fs from 'fs';

// Initialize the client with your API key
const client = new Chunkr({ apiKey: 'your_api_key' });

// Parse a document from URL
const url = 'https://example.com/document.pdf';
const task = await client.tasks.parse.create({ file: url });

// OR parse from local file
// const file = await client.files.create({ 
//     file: fs.createReadStream('./document.pdf') 
// });
// const task = await client.tasks.parse.create({ file: file.url });

console.log(`Task created with ID: ${task.task_id}`);

// Wait for the task to complete
const completedTask = await client.tasks.get(task.task_id, {
    wait_for_completion: true
});

// Access the chunks from the output
if (completedTask.status === "Succeeded") {
    console.log(`Document has ${completedTask.output.chunks.length} chunks.`);
    // `chunk.content` holds the structured representation
    for (const chunk of completedTask.output.chunks) {
        console.log(chunk.content);
    }
} else {
    console.log(`Task failed with status: ${completedTask.status}`);
}
````

```bash cURL
# 1. Create a parse task
# Copy the `task_id` from the response
curl -X POST https://api.chunkr.ai/api/v1/tasks/parse \
  --header "Authorization: YOUR_API_KEY" \
  --header "Content-Type: application/json" \
  --data '{
    "file": "https://example.com/document.pdf"
  }'

# 2. Poll the Get Task endpoint until status is "Succeeded"
# Once complete, the response will contain the output with chunks
curl -X GET https://api.chunkr.ai/api/v1/tasks/{your_task_id} \
  --header "Authorization: YOUR_API_KEY"
````

</CodeGroup>

---

<Tip>
  Our default configuration is optimized through extensive testing and provides
  excellent results for most documents. You can customize parse if you have specific
  requirements.
</Tip>

<Accordion title="Advanced Configuration">

While our defaults work exceptionally well for almost all use cases, Parse offers extensive customization options for specialized needs:

- **[Pipeline (`pipeline`)](/docs/features/pipeline)**: Choose the provider (`Azure` or `Chunkr`) for layout analysis and OCR models.
- **Layout Analysis & OCR**:
  - _Segmentation Strategy (`segmentation_strategy`)_: Choose between `LayoutAnalysis` (default) or a full-page VLM approach for parsing.
  - _OCR Strategy (`ocr_strategy`)_: Use `Auto` to selectively apply OCR or `All` to force it on every page.
- **[Segment-level Customization (`segment_processing`)](/docs/features/segment-processing)**: Control processing for each document element (e.g., `Text`, `Table`, `Picture`):
  - _Processing Strategy (`strategy`)_: For each segment, set the strategy to generate HTML/Markdown. `Auto` (simple OCR + logic), `LLM` (VLM generation), or `Ignore` (remove from output).
  - _Format Control (`format`)_: Control the output format (`Markdown` or `HTML`) for segment content.
  - _Extended Context (`extended_context`)_: Provide the full page image as additional context for VLM processing of a segment. Useful for cases like distant legends for tables and pictures.
  - _Cropped Images (`crop_image`)_: Control if a cropped image of the segment is included.
- **[Chunking (`chunk_processing`)](/docs/features/chunking)**: Configure chunking strategy, sizes, and token-counting model.
- **[LLM Processing (`llm_processing`)](/docs/features/llm-processing)**: Select the VLM provider and model for all VLM tasks.
- **[Error Handling (`error_handling`)](/docs/features/error-handling)**: Set to `Fail` (default) to stop on any error, or `Continue` to process despite non-critical errors.

</Accordion>
