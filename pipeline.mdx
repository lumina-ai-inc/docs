- **Document Segmentation**:

  - **Vision Grid Transformer (VGT)**: Utilizes GPU-accelerated VGT models ([arXiv](https://arxiv.org/abs/2308.14978)) to perform comprehensive document layout analysis, accurately identifying and extracting various sections such as tables, figures, text, headers, and footers.

  - **LightGBM (GBM)**: Employs CPU-based LightGBM models ([Documentation](https://lightgbm.readthedocs.io/en/stable/)) for efficient segmentation and classification, enabling quick processing without requiring intensive GPU resources.

  - **Docker - PDLA**: Deploys segmentation services using Docker containers with PDLA ([GitHub](https://github.com/huridocs/pdf-document-layout-analysis)) to ensure scalable and consistent performance across different environments.

- **OCR (Optical Character Recognition)**: Utilizes [PaddleOCR](https://github.com/PaddlePaddle/PaddleOCR) to accurately extract text from images and structured tables.

- **Structured Extraction**: Leverages Chunkr's structured extraction capabilities to convert unstructured document content into structured data formats according to a defined JSON schema. Refer to the [structured extraction documentation](/structured_extraction) for more details.

  - **Output**: Structured data containing chunk lengths and detailed segment information, including bounding boxes, extracted text, and associated metadata.

  _Note:_ The segments within bounding boxes are relative to each other, maintaining a hierarchical relationship between segments and their OCR data.
